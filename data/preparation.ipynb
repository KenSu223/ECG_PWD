{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "random.seed(2024)\n",
    "\n",
    "from skimage.transform import resize\n",
    "import pywt\n",
    "import os\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.signal import correlate, hilbert, butter, firwin, filtfilt, lfilter \n",
    "import scipy.io\n",
    "from scipy.signal import resample_poly\n",
    "from scipy.spatial.distance import cdist\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='/labs/cliffordlab/fetal/leipzig/Version2/'\n",
    "Annot_path_1='/labs/cliffordlab/fetal/leipzig/Annotations/ManualAnnotations/Beat_annotationAnno1'\n",
    "Annot_path_2='/labs/cliffordlab/fetal/leipzig/Annotations/ManualAnnotations/Beat_annotationAnno2'\n",
    "\n",
    "file_names=['CB300482IIIV2','MZ290383V2','RM040883IIV2','SB280780_1V2', 'AK101197V2', 'BA120381V2','KF221288V2','SZ290877V2']\n",
    "\n",
    "signals = [np.squeeze(scipy.io.loadmat(file_path+file)['doppler']) for file in file_names]\n",
    "ECGs=[np.squeeze(scipy.io.loadmat(file_path+file)['fECG']) for file in file_names]\n",
    "\n",
    "fECG_1 = scipy.io.loadmat('./AK101197_fECG.mat')['all']\n",
    "fECG_6 = scipy.io.loadmat('./BA120381_fECG.mat')['all']\n",
    "fECG_7 = scipy.io.loadmat('./KF221288_fECG.mat')['all']\n",
    "fECG_8 = scipy.io.loadmat('./SZ290877_fECG.mat')['all']\n",
    "\n",
    "ECGs_2 = ECGs[:-4]\n",
    "ECGs_2.append(fECG_1)\n",
    "ECGs_2.append(fECG_6)\n",
    "ECGs_2.append(fECG_7)\n",
    "ECGs_2.append(fECG_8)\n",
    "ECG_sigs = ECGs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQI_1 = []\n",
    "SQI_2 = []\n",
    "ECG_1=[]\n",
    "ECG_2=[]\n",
    "ECG_SQIC_1=[]\n",
    "ECG_SQIC_2=[]\n",
    "ECG_SQI_1=[]\n",
    "ECG_SQI_2=[]\n",
    "\n",
    "file_names_old=['CB300482IIIV2','MZ290383V2','RM040883IIV2','SB280780_1V2', 'AK101197V2']\n",
    "\n",
    "for file in file_names_old:\n",
    "    SQI_path_1 = Annot_path_1 + '/' + file + '_Doppler_SQI.txt'\n",
    "    SQI_path_2 = Annot_path_2 + '/' + file + '_Doppler_SQI.txt'\n",
    "    \n",
    "    SQI_data_1 = np.loadtxt(SQI_path_1, delimiter=',')\n",
    "    SQI_1.append(SQI_data_1)\n",
    "    \n",
    "    SQI_data_2 = np.loadtxt(SQI_path_2, delimiter=',')\n",
    "    SQI_2.append(SQI_data_2)\n",
    "    \n",
    "    ECG_SQIC_1=[]\n",
    "    ECG_SQIC_2=[]\n",
    "    for i in range(1,8):\n",
    "        ECG_path_1 = Annot_path_1 + '/' + file + f'_{i}_SQI.txt'\n",
    "        ECG_path_2 = Annot_path_2 + '/' + file + f'_{i}_SQI.txt'\n",
    "        \n",
    "        ECG_SQI1 = np.loadtxt(ECG_path_1, delimiter=',')\n",
    "        ECG_SQIC_1.append(ECG_SQI1)\n",
    "        ECG_SQI2 = np.loadtxt(ECG_path_2, delimiter=',')\n",
    "        ECG_SQIC_2.append(ECG_SQI2)\n",
    "        \n",
    "    ECG_SQI_1.append(ECG_SQIC_1)\n",
    "    ECG_SQI_2.append(ECG_SQIC_2)\n",
    "    \n",
    "file_names_new=['BA120381V2','KF221288V2','SZ290877V2']\n",
    "\n",
    "for file in file_names_new:\n",
    "    SQI_path_1 = './Additional_data/SQIs/' + file + '_Doppler_SQI.txt'\n",
    "    SQI_path_2 = './Additional_data/SQIs/' + file + '_Doppler_SQI.txt'\n",
    "    \n",
    "    SQI_data_1 = np.loadtxt(SQI_path_1, delimiter=',')\n",
    "    SQI_1.append(SQI_data_1)\n",
    "    \n",
    "    SQI_data_2 = np.loadtxt(SQI_path_2, delimiter=',')\n",
    "    SQI_2.append(SQI_data_2)\n",
    "    \n",
    "    ECG_SQIC_1=[]\n",
    "    ECG_SQIC_2=[]\n",
    "    for i in range(1,8):\n",
    "        ECG_path_1 = './Additional_data/SQIs/' + file + f'_{i}_SQI.txt'\n",
    "        ECG_path_2 = './Additional_data/SQIs/' + file + f'_{i}_SQI.txt'\n",
    "        \n",
    "        ECG_SQI1 = np.loadtxt(ECG_path_1, delimiter=',')\n",
    "        ECG_SQIC_1.append(ECG_SQI1)\n",
    "        ECG_SQI2 = np.loadtxt(ECG_path_2, delimiter=',')\n",
    "        ECG_SQIC_2.append(ECG_SQI2)\n",
    "        \n",
    "    ECG_SQI_1.append(ECG_SQIC_1)\n",
    "    ECG_SQI_2.append(ECG_SQIC_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECG_1=[]\n",
    "ECG_2=[]\n",
    "\n",
    "for file in file_names:\n",
    "    if file == 'SZ290877V2':\n",
    "        ECG_1.append(np.loadtxt('./Additional_data/SQIs/SZ290877V2_2.txt', delimiter=','))\n",
    "        ECG_2.append(np.loadtxt('./Additional_data/SQIs/SZ290877V2_2.txt', delimiter=','))\n",
    "    elif file == 'KF221288V2':\n",
    "        ECG_1.append(np.loadtxt('./Additional_data/SQIs/KF221288V2_2.txt', delimiter=','))\n",
    "        ECG_2.append(np.loadtxt('./Additional_data/SQIs/KF221288V2_2.txt', delimiter=','))\n",
    "    elif file == 'BA120381V2':\n",
    "        ECG_path_1 = Annot_path_1 + '/' + file + '_2.txt'\n",
    "        ECG_data_1 = np.loadtxt(ECG_path_1, delimiter=',')\n",
    "        ECG_1.append(ECG_data_1[:,0])\n",
    "        ECG_2.append(ECG_data_1[:,0])\n",
    "\n",
    "    else:\n",
    "        ECG_path_1 = Annot_path_1 + '/' + file + '_2.txt'\n",
    "        ECG_path_2 = Annot_path_2 + '/' + file + '_2.txt'\n",
    "\n",
    "        ECG_data_1 = np.loadtxt(ECG_path_1, delimiter=',')\n",
    "        ECG_1.append(ECG_data_1[:,0])\n",
    "        \n",
    "        ECG_data_2 = np.loadtxt(ECG_path_2, delimiter=',')\n",
    "        ECG_2.append(ECG_data_2[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_index(lst, number):\n",
    "    differences = [abs(x - number) for x in lst]\n",
    "    closest_index = differences.index(min(differences))\n",
    "\n",
    "    return closest_index\n",
    "\n",
    "def modify_array(arr, limit):\n",
    "    length = arr.shape[0]\n",
    "    if length > limit:\n",
    "        return arr[:limit]\n",
    "    elif length < limit:\n",
    "        padding_length = limit - length\n",
    "        return np.pad(arr, (0, padding_length), 'constant', constant_values=(np.mean(arr),))\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "def normalize_one(array):\n",
    "    ecg_min = np.min(array)\n",
    "    ecg_max = np.max(array)\n",
    "    \n",
    "    normalized_ecg = 2 * (array - ecg_min) / (ecg_max - ecg_min) - 1\n",
    "    \n",
    "    return normalized_ecg\n",
    "    \n",
    "def normalize(array):\n",
    "    return (array - array.min())/(array.max() - array.min()) \n",
    "\n",
    "def normalize_mean_std(array):\n",
    "    mean = np.mean(array)\n",
    "    std = np.std(array)\n",
    "    normalized_array = (array - mean) / std\n",
    "    return normalized_array\n",
    "\n",
    "\n",
    "def convert_to_float(byte_string):\n",
    "    string = byte_string.decode('utf-8')  # Decode byte string to a regular string\n",
    "    number_str = string.split(',')[0]  # Split at the comma and take the first part\n",
    "    return float(number_str)  # Convert to float\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='bandpass')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def DUS_filtering(DUS, fs):  \n",
    "    #25-600Hz 4th order Butterworth band pass\n",
    "    lowcut = 25.0\n",
    "    highcut = 600.0\n",
    "    DUS_f = butter_bandpass_filter(DUS, lowcut, highcut, fs, order=2)\n",
    "    return DUS_f\n",
    "\n",
    "def signal_resample(signal, original_fs, target_fs):\n",
    "    gcd = np.gcd(original_fs, target_fs)\n",
    "    up = target_fs // gcd\n",
    "    down = original_fs // gcd\n",
    "    resampled_signal=resample_poly(signal, up, down)\n",
    "    return resampled_signal\n",
    "\n",
    "\n",
    "def ECG_filtering(ecg_signal, sample_rate):\n",
    "    pass_band = [3, 45]  # Pass band frequencies (Hz)\n",
    "    \n",
    "    # Nyquist frequency\n",
    "    nyquist_rate = sample_rate / 2.0\n",
    "    \n",
    "    # Calculate the filter coefficients\n",
    "    numtaps = 101  # Number of taps in the FIR filter\n",
    "    fir_coefficients = firwin(numtaps, [pass_band[0] / nyquist_rate, pass_band[1] / nyquist_rate], pass_zero=False)\n",
    "    \n",
    "    # Apply the filter\n",
    "    filtered_signal = filtfilt(fir_coefficients, 1, ecg_signal)\n",
    "    \n",
    "    return filtered_signal\n",
    "\n",
    "\n",
    "\n",
    "def findClosersDuplicates(beats, threshold):\n",
    "    \"\"\"\n",
    "    Remove duplicates from beats array based on a threshold.\n",
    "    \"\"\"\n",
    "    unique_beats = []\n",
    "    prev_beat = -np.inf\n",
    "    for beat in sorted(beats):\n",
    "        if beat - prev_beat > threshold:\n",
    "            unique_beats.append(beat)\n",
    "            prev_beat = beat\n",
    "    return np.array(unique_beats)\n",
    "\n",
    "def groupingBeats_leipzig(beats1, beats2, fs):\n",
    "    beats1 = findClosersDuplicates(beats1, 0.24 * fs)\n",
    "    beats2 = findClosersDuplicates(beats2, 0.24 * fs)\n",
    "\n",
    "    D = cdist(beats1[:, np.newaxis], beats2[:, np.newaxis]) #distance between a beat from beats1 and a beat from beats2\n",
    "\n",
    "    idxMinBeats1 = np.argmin(D, axis=1)\n",
    "    idxMinBeats2 = np.argmin(D, axis=0)\n",
    "\n",
    "    beatSet = []\n",
    "    \n",
    "    if len(np.unique(idxMinBeats1)) == len(beats1):\n",
    "        for i in range(len(beats1)):\n",
    "            beatSet.append(np.mean([beats1[i], beats2[idxMinBeats1[i]]]))\n",
    "        \n",
    "        if len(beats1) != len(beats2):\n",
    "            missingBeats2 = np.setdiff1d(range(len(beats2)), idxMinBeats1)\n",
    "            for i in missingBeats2:\n",
    "                beatSet.append(beats2[i])\n",
    "    else:\n",
    "        uniqueBeats2 = np.unique(idxMinBeats1)\n",
    "        \n",
    "        for i in uniqueBeats2:\n",
    "            idxBeat1 = np.where(idxMinBeats1 == i)[0]\n",
    "            \n",
    "            if len(idxBeat1) == 1:\n",
    "                beatSet.append(np.mean([beats1[idxBeat1[0]], beats2[i]]))\n",
    "            else:\n",
    "                closerBeat1FromBeat2 = idxMinBeats2[i]\n",
    "                beatSet.append(np.mean([beats1[closerBeat1FromBeat2], beats2[i]]))\n",
    "                extras = beats1[np.setdiff1d(idxBeat1, closerBeat1FromBeat2)]\n",
    "                beatSet.extend(extras)\n",
    "\n",
    "    return sorted(beatSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECG_ranking_indices = scipy.io.loadmat('./VotingRanking_allch_DSQI.mat')['indices']\n",
    "ECG_ranking_indices_all = []\n",
    "def extract_numbers(data):\n",
    "    # Initialize an empty list to store the results\n",
    "    result = []\n",
    "    # Loop through each row\n",
    "    for row in data:\n",
    "        # Loop through each column in the row\n",
    "        inner_list = []\n",
    "        for col in row:\n",
    "            # Extract the innermost number and append to the inner list\n",
    "            inner_list.append(col[0][0])\n",
    "        # Append the inner list to the result list\n",
    "        result.append(inner_list)\n",
    "    return np.array(result)\n",
    "    \n",
    "indices_data_1 = extract_numbers(ECG_ranking_indices[0][0])\n",
    "indices_data_2 = extract_numbers(ECG_ranking_indices[1][0])\n",
    "indices_data_3 = extract_numbers(ECG_ranking_indices[2][0])\n",
    "indices_data_4 = extract_numbers(ECG_ranking_indices[3][0])\n",
    "indices_data_5 = extract_numbers(ECG_ranking_indices[4][0])\n",
    "indices_data_6 = extract_numbers(ECG_ranking_indices[5][0])\n",
    "indices_data_7 = extract_numbers(ECG_ranking_indices[6][0])\n",
    "indices_data_8 = extract_numbers(ECG_ranking_indices[7][0])\n",
    "\n",
    "ECG_ranking_indices_all.append(indices_data_1[:,-1])\n",
    "ECG_ranking_indices_all.append(indices_data_2[:,-1])\n",
    "ECG_ranking_indices_all.append(indices_data_3[:,-1])\n",
    "ECG_ranking_indices_all.append(indices_data_4[:,-1])\n",
    "ECG_ranking_indices_all.append(indices_data_5[:,-1])\n",
    "ECG_ranking_indices_all.append(indices_data_6[:,-1])\n",
    "ECG_ranking_indices_all.append(indices_data_7[:,-1])\n",
    "ECG_ranking_indices_all.append(indices_data_8[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doppler-fECG heartbeat extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_ECG=1000\n",
    "target_fs_Doppler=2000\n",
    "target_fs_ECG=250\n",
    "\n",
    "win_len=3.75\n",
    "\n",
    "DUS_list_all_1 = []\n",
    "ECG_list_all_1 = []\n",
    "DUS_list_all_2 = []\n",
    "ECG_list_all_2 = []\n",
    "DUS_list_all_3 = []\n",
    "ECG_list_all_3 = []\n",
    "DUS_list_all_4 = []\n",
    "ECG_list_all_4 = []\n",
    "DUS_list_all_5 = []\n",
    "ECG_list_all_5 = []\n",
    "DUS_list_all_6 = []\n",
    "ECG_list_all_6 = []\n",
    "DUS_list_all_7 = []\n",
    "ECG_list_all_7 = []\n",
    "DUS_list_all_8 = []\n",
    "ECG_list_all_8 = []\n",
    "\n",
    "DUS_list_all_train_1 = []\n",
    "ECG_list_all_train_1 = []\n",
    "DUS_list_all_train_2 = []\n",
    "ECG_list_all_train_2 = []\n",
    "DUS_list_all_train_3 = []\n",
    "ECG_list_all_train_3 = []\n",
    "DUS_list_all_train_4 = []\n",
    "ECG_list_all_train_4 = []\n",
    "DUS_list_all_train_5 = []\n",
    "ECG_list_all_train_5 = []\n",
    "DUS_list_all_train_6 = []\n",
    "ECG_list_all_train_6 = []\n",
    "DUS_list_all_train_7 = []\n",
    "ECG_list_all_train_7 = []\n",
    "DUS_list_all_train_8 = []\n",
    "ECG_list_all_train_8 = []\n",
    "    \n",
    "tensor_all_list_all = []\n",
    "label_list_all = []\n",
    "beatset_list_all= []\n",
    "FHR_list_all= []\n",
    "DUS_list_all = []\n",
    "ECG_list_all = []\n",
    "\n",
    "adj = [-17,-13,-29,-11,-14,0,0,2]\n",
    "\n",
    "t_Doppler = np.linspace(0, 3.75, 7500)\n",
    "t_ECG = np.linspace(0, 3.75, 938)\n",
    "g_segments = 0\n",
    "\n",
    "for signal_num, signal_name in enumerate(file_names):\n",
    "    print(signal_name)\n",
    "    \n",
    "    if file_names[signal_num]=='MZ290383V2':\n",
    "        fs_Doppler=10000\n",
    "    else:\n",
    "        fs_Doppler=20000\n",
    "        \n",
    "    SQI_len=min(len(SQI_1[signal_num]),len(SQI_2[signal_num]))\n",
    "    \n",
    "    for page in range(SQI_len):\n",
    "        \n",
    "        if SQI_1[signal_num][page]==1 and SQI_2[signal_num][page]==1:\n",
    "\n",
    "            start_time=page*win_len\n",
    "            end_time=(page+1)*win_len\n",
    "\n",
    "            start_Index_ECG = start_time*fs_ECG\n",
    "            end_Index_ECG = end_time*fs_ECG\n",
    "\n",
    "            start_Index_Doppler = start_time*fs_Doppler\n",
    "            end_Index_Doppler = end_time*fs_Doppler\n",
    "\n",
    "            ECG_page_anno1 = ECG_1[signal_num][(ECG_1[signal_num] >= start_Index_ECG) & (ECG_1[signal_num] <= end_Index_ECG)]\n",
    "            ECG_page_anno2 = ECG_2[signal_num][(ECG_2[signal_num] >= start_Index_ECG) & (ECG_2[signal_num] <= end_Index_ECG)]\n",
    "\n",
    "\n",
    "            beatSet = groupingBeats_leipzig(ECG_page_anno1, ECG_page_anno2,fs_ECG)\n",
    "            beatSet_time=np.array(beatSet)/fs_ECG-start_time\n",
    "\n",
    "\n",
    "            diffFHR = []\n",
    "            for bIdx in range(1, len(beatSet)):\n",
    "                if beatSet[bIdx] - beatSet[bIdx - 1] <= fs_ECG * (2 / 3): #Greater than 90 bpm\n",
    "                    diffFHR.append(beatSet[bIdx] - beatSet[bIdx - 1])\n",
    "                    \n",
    "            #FHR_all=60 / (np.array(diffFHR) / fs_ECG)\n",
    "            #FHR = 60 / np.median(np.array(diffFHR) / fs_ECG)\n",
    "\n",
    "            ECG_SQI_CH_1 = []\n",
    "            ECG_SQI_CH_2 = []\n",
    "            \n",
    "            for i in range(7): \n",
    "                ECG_SQI_CH_1.append(ECG_SQI_1[signal_num][i][page])\n",
    "                ECG_SQI_CH_2.append(ECG_SQI_2[signal_num][i][page])\n",
    "                \n",
    "            one_sqi_channels = np.where((np.array(ECG_SQI_CH_1) == 1) & (np.array(ECG_SQI_CH_2) == 1))[0]\n",
    "\n",
    "            if one_sqi_channels.size > 1:\n",
    "                ranking = ECG_ranking_indices_all[signal_num][page*7:(page+1)*7]\n",
    "                set_intersection = set(one_sqi_channels).intersection(ranking)\n",
    "                sqi = [x for x in one_sqi_channels if x in set_intersection][0]\n",
    "            elif one_sqi_channels.size == 1:\n",
    "                sqi = one_sqi_channels[0]\n",
    "\n",
    "            sqi_sum = [x + y for x, y in zip(ECG_SQI_CH_1, ECG_SQI_CH_2)]\n",
    "            if all(value > 5 for value in sqi_sum) or ECG_SQI_CH_1 == 5 or ECG_SQI_CH_2 == 5:\n",
    "                continue\n",
    "            \n",
    "            else:\n",
    "                sqi_sum = [x + y for x, y in zip(ECG_SQI_CH_1, ECG_SQI_CH_2)]\n",
    "                min_sqi_sum = np.min(sqi_sum)\n",
    "                candidates = np.where(sqi_sum == min_sqi_sum)[0]\n",
    "                if len(candidates) > 1:\n",
    "                    cd_inx = candidates.tolist()[0]\n",
    "                    min_sqi_1 = np.min(ECG_SQI_CH_1[cd_inx])\n",
    "                    min_sqi_2 = np.min(ECG_SQI_CH_2[cd_inx])\n",
    "            \n",
    "                    final_candidates = [c for c in candidates if ECG_SQI_CH_1[c] == min_sqi_1 or ECG_SQI_CH_2[c] == min_sqi_2]\n",
    "            \n",
    "                    if len(final_candidates) > 1:\n",
    "                        ranking = ECG_ranking_indices_all[signal_num][page*7:(page+1)*7]\n",
    "                        set_intersection = set(final_candidates).intersection(ranking)\n",
    "                        sqi = [c for c in final_candidates if c in set_intersection][0]\n",
    "                    else:\n",
    "                        sqi = int(final_candidates[0])\n",
    "                else:\n",
    "                    sqi = int(candidates[0])\n",
    "\n",
    "            g_segments += 1\n",
    "            ECG=ECG_sigs[signal_num][sqi][int(start_Index_ECG):int(end_Index_ECG)]\n",
    "            ECG=signal_resample(ECG, fs_ECG, target_fs_ECG)\n",
    "            ECG=ECG_filtering(ECG, target_fs_ECG)\n",
    "            ECG=np.roll(normalize_one(ECG), adj[signal_num])\n",
    "\n",
    "            windowed_rec_original=signals[signal_num][int(start_Index_Doppler):int(end_Index_Doppler)]\n",
    "\n",
    "            windowed_rec_resampled=signal_resample(windowed_rec_original, fs_Doppler, target_fs_Doppler)\n",
    "            windowed_rec=DUS_filtering(windowed_rec_resampled, target_fs_Doppler)\n",
    "            windowed_rec=normalize_one(windowed_rec)\n",
    "\n",
    "            for i in range(len(beatSet_time)):\n",
    "                if (i == len(beatSet_time) - 2):\n",
    "                    break\n",
    "                \n",
    "                i_d = find_closest_index(t_Doppler, beatSet_time[i])\n",
    "                i_d_1 = find_closest_index(t_Doppler, beatSet_time[i+1])\n",
    "                i_d_2 = find_closest_index(t_Doppler, beatSet_time[i+2])\n",
    "                \n",
    "                i_t = find_closest_index(t_ECG, beatSet_time[i])\n",
    "                i_t_1 = find_closest_index(t_ECG, beatSet_time[i+1])\n",
    "                i_t_2 = find_closest_index(t_ECG, beatSet_time[i+2])\n",
    "\n",
    "\n",
    "                windowed_rec_beat = windowed_rec[round((i_d_1+i_d)/2):round((i_d_2+i_d_1)/2)]\n",
    "                windowed_rec_beat = normalize_one(windowed_rec_beat)\n",
    "                windowed_rec_beat = modify_array(windowed_rec_beat,800)\n",
    "                \n",
    "                ECG_beat = ECG[round((i_t_1+i_t)/2):round((i_t_2+i_t_1)/2)]\n",
    "                ECG_beat=normalize_one(ECG_beat)\n",
    "                ECG_beat = modify_array(ECG_beat,100)\n",
    "\n",
    "\n",
    "                if file_names[signal_num]=='AK101197V2':\n",
    "                    DUS_list_all_1.append(windowed_rec_beat)\n",
    "                    ECG_list_all_1.append(ECG_beat)\n",
    "                               \n",
    "                if file_names[signal_num]=='CB300482IIIV2':\n",
    "                    DUS_list_all_2.append(windowed_rec_beat)\n",
    "                    ECG_list_all_2.append(ECG_beat)\n",
    "                                \n",
    "                if file_names[signal_num]=='MZ290383V2':\n",
    "                    DUS_list_all_3.append(windowed_rec_beat)\n",
    "                    ECG_list_all_3.append(ECG_beat)                    \n",
    "                               \n",
    "                if file_names[signal_num]=='RM040883IIV2':\n",
    "                    DUS_list_all_4.append(windowed_rec_beat)\n",
    "                    ECG_list_all_4.append(ECG_beat)                   \n",
    "                                \n",
    "                if file_names[signal_num]=='SB280780_1V2':\n",
    "                    DUS_list_all_5.append(windowed_rec_beat)\n",
    "                    ECG_list_all_5.append(ECG_beat)    \n",
    "\n",
    "                if file_names[signal_num]=='BA120381V2':\n",
    "                    DUS_list_all_6.append(windowed_rec_beat)\n",
    "                    ECG_list_all_6.append(ECG_beat)\n",
    "                               \n",
    "                if file_names[signal_num]=='KF221288V2':\n",
    "                    DUS_list_all_7.append(windowed_rec_beat)\n",
    "                    ECG_list_all_7.append(ECG_beat)\n",
    "                                \n",
    "                if file_names[signal_num]=='SZ290877V2':\n",
    "                    DUS_list_all_8.append(windowed_rec_beat)\n",
    "                    ECG_list_all_8.append(ECG_beat)                    \n",
    "                               \n",
    "\n",
    "DUS_list_all_1=np.array(DUS_list_all_1, dtype=object)\n",
    "ECG_list_all_1=np.array(ECG_list_all_1, dtype=object)\n",
    "DUS_list_all_2=np.array(DUS_list_all_2, dtype=object)\n",
    "ECG_list_all_2=np.array(ECG_list_all_2, dtype=object)\n",
    "DUS_list_all_3=np.array(DUS_list_all_3, dtype=object)\n",
    "ECG_list_all_3=np.array(ECG_list_all_3, dtype=object)\n",
    "DUS_list_all_4=np.array(DUS_list_all_4, dtype=object)\n",
    "ECG_list_all_4=np.array(ECG_list_all_4, dtype=object)\n",
    "DUS_list_all_5=np.array(DUS_list_all_5, dtype=object)\n",
    "ECG_list_all_5=np.array(ECG_list_all_5, dtype=object)\n",
    "DUS_list_all_6=np.array(DUS_list_all_6, dtype=object)\n",
    "ECG_list_all_6=np.array(ECG_list_all_6, dtype=object)\n",
    "DUS_list_all_7=np.array(DUS_list_all_7, dtype=object)\n",
    "ECG_list_all_7=np.array(ECG_list_all_7, dtype=object)\n",
    "DUS_list_all_8=np.array(DUS_list_all_8, dtype=object)\n",
    "ECG_list_all_8=np.array(ECG_list_all_8, dtype=object)\n",
    "\n",
    "\n",
    "np.savez('./Train_addition/Leipzing_heartbeat_DUS_FECG_1.npz', DUS_list_all=DUS_list_all_1, ECG_list_all=ECG_list_all_1)\n",
    "np.savez('./Train_addition/Leipzing_heartbeat_DUS_FECG_2.npz', DUS_list_all=DUS_list_all_2, ECG_list_all=ECG_list_all_2)\n",
    "np.savez('./Train_addition/Leipzing_heartbeat_DUS_FECG_3.npz', DUS_list_all=DUS_list_all_3, ECG_list_all=ECG_list_all_3)\n",
    "np.savez('./Train_addition/Leipzing_heartbeat_DUS_FECG_4.npz', DUS_list_all=DUS_list_all_4, ECG_list_all=ECG_list_all_4)\n",
    "np.savez('./Train_addition/Leipzing_heartbeat_DUS_FECG_5.npz', DUS_list_all=DUS_list_all_5, ECG_list_all=ECG_list_all_5)\n",
    "np.savez('./Train_addition/Leipzing_heartbeat_DUS_FECG_6.npz', DUS_list_all=DUS_list_all_6, ECG_list_all=ECG_list_all_6)\n",
    "np.savez('./Train_addition/Leipzing_heartbeat_DUS_FECG_7.npz', DUS_list_all=DUS_list_all_7, ECG_list_all=ECG_list_all_7)\n",
    "np.savez('./Train_addition/Leipzing_heartbeat_DUS_FECG_8.npz', DUS_list_all=DUS_list_all_8, ECG_list_all=ECG_list_all_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML model SQI prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from fastdtw import fastdtw\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, f1_score, RocCurveDisplay\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.signal import butter, filtfilt, hilbert, welch, lfilter, correlate\n",
    "from scipy.stats import weightedtau\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.stats import skew, kurtosis\n",
    "from catboost import CatBoostClassifier\n",
    "import nolds\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECG_6 = scipy.io.loadmat('/Users/alirezarafiei/Desktop/sqi/ECG_6_all_ch_ASQI.mat')['data']\n",
    "ECG_7 = scipy.io.loadmat('/Users/alirezarafiei/Desktop/sqi/ECG_7_all_ch_ASQI.mat')['data']\n",
    "ECG_8 = scipy.io.loadmat('/Users/alirezarafiei/Desktop/sqi/ECG_8_all_ch_ASQI.mat')['data']\n",
    "\n",
    "Doppler_6 = scipy.io.loadmat('/Users/alirezarafiei/Desktop/sqi/Doppler_6_ASQI.mat')['data'].T\n",
    "Doppler_7 = scipy.io.loadmat('/Users/alirezarafiei/Desktop/sqi/Doppler_7_ASQI.mat')['data'].T\n",
    "Doppler_8 = scipy.io.loadmat('/Users/alirezarafiei/Desktop/sqi/Doppler_8_ASQI.mat')['data'].T\n",
    "\n",
    "indices_add = scipy.io.loadmat('/Users/alirezarafiei/Desktop/sqi/ECG_indices_additional_data_ASQI.mat')['indices']\n",
    "\n",
    "dtw_dist_lag_6 = np.load('/Users/alirezarafiei/Desktop/sqi/dtw_dist_lag_6.npy')\n",
    "dtw_dist_lag_7 = np.load('/Users/alirezarafiei/Desktop/sqi/dtw_dist_lag_7.npy')\n",
    "dtw_dist_lag_8 = np.load('/Users/alirezarafiei/Desktop/sqi/dtw_dist_lag_8.npy')\n",
    "\n",
    "correlations_lag_6 = np.load('/Users/alirezarafiei/Desktop/sqi/correlations_lag_6.npy')\n",
    "correlations_lag_7 = np.load('/Users/alirezarafiei/Desktop/sqi/correlations_lag_7.npy')\n",
    "correlations_lag_8 = np.load('/Users/alirezarafiei/Desktop/sqi/correlations_lag_8.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numbers(data):\n",
    "    # Initialize an empty list to store the results\n",
    "    result = []\n",
    "    # Loop through each row\n",
    "    for row in data:\n",
    "        # Loop through each column in the row\n",
    "        inner_list = []\n",
    "        for col in row:\n",
    "            # Extract the innermost number and append to the inner list\n",
    "            inner_list.append(col[0][0])\n",
    "        # Append the inner list to the result list\n",
    "        result.append(inner_list)\n",
    "    return np.array(result)\n",
    "Feature_indices_6 = extract_numbers(indices_add[0][0])\n",
    "Feature_indices_7 = extract_numbers(indices_add[1][0])\n",
    "Feature_indices_8 = extract_numbers(indices_add[2][0])\n",
    "\n",
    "indices_indices_all = np.concatenate([Feature_indices_6,Feature_indices_7,Feature_indices_8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_envelope(signal):\n",
    "    analytic_signal = hilbert(signal)\n",
    "    envelope = np.abs(analytic_signal)\n",
    "    return envelope\n",
    "\n",
    "def homomorphic_envelope_processed(input_signal, fs=20000, lpf_frequency=8):\n",
    "    B_low, A_low = butter(1, 2 * lpf_frequency / fs, 'low')\n",
    "    analytic_signal = hilbert(input_signal)\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "    log_amplitude_envelope = np.log(amplitude_envelope)\n",
    "    filtered_log_envelope = filtfilt(B_low, A_low, log_amplitude_envelope)\n",
    "    homomorphic_envelope = np.exp(filtered_log_envelope)\n",
    "    \n",
    "    # Remove spurious spikes in first sample\n",
    "    if len(homomorphic_envelope) > 1:\n",
    "        homomorphic_envelope[0] = homomorphic_envelope[1]\n",
    "\n",
    "    # Min-max normalization to range [0, 1]\n",
    "    if homomorphic_envelope.ndim == 2:\n",
    "        normalized_homomorphic_envelope = np.zeros_like(homomorphic_envelope)\n",
    "        for i in range(homomorphic_envelope.shape[0]):\n",
    "            min_val = np.min(homomorphic_envelope[i, :])\n",
    "            max_val = np.max(homomorphic_envelope[i, :])\n",
    "            normalized_homomorphic_envelope[i, :] = (homomorphic_envelope[i, :] - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        min_val = np.min(homomorphic_envelope)\n",
    "        max_val = np.max(homomorphic_envelope)\n",
    "        normalized_homomorphic_envelope = (homomorphic_envelope - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return normalized_homomorphic_envelope\n",
    "\n",
    "def normalize_zero_one(array):\n",
    "    ecg_min = np.min(array)\n",
    "    ecg_max = np.max(array)\n",
    "    \n",
    "    normalized_ecg = 2 * (array - ecg_min) / (ecg_max - ecg_min)\n",
    "\n",
    "    if array.ndim == 2:\n",
    "        normalized_array = np.zeros_like(array)\n",
    "        for i in range(array.shape[0]):\n",
    "            min_val = np.min(array[i, :])\n",
    "            max_val = np.max(array[i, :])\n",
    "            normalized_array[i, :] = (array[i, :] - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        min_val = np.min(array)\n",
    "        max_val = np.max(array)\n",
    "        normalized_array = (array - min_val) / (max_val - min_val)\n",
    "    \n",
    "    return normalized_array\n",
    "def butter_bandpass(data, lowcut, highcut, fs=1000, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def pan_tompkins_envelope_processed(ecg_signals, lowcut=8, highcut=80, fs=1000):\n",
    "    envelopes = []\n",
    "\n",
    "    for ecg_signal in ecg_signals:\n",
    "        # Filter ECG signal between 8 Hz and 80 Hz\n",
    "        ecg_filtered = butter_bandpass(ecg_signal, lowcut, highcut, fs)\n",
    "\n",
    "        # Differentiation\n",
    "        diff = np.diff(ecg_filtered, prepend=ecg_filtered[0])\n",
    "\n",
    "        # Squaring\n",
    "        squared = diff**2\n",
    "\n",
    "        # Moving Window Integration\n",
    "        window_length = int(0.05 * fs)  \n",
    "        window = np.ones(window_length) / window_length\n",
    "        integrated = np.convolve(squared, window, mode='same')\n",
    "\n",
    "        # Extracting the envelope using the Hilbert transform\n",
    "        envelope = np.abs(hilbert(integrated))\n",
    "        envelopes.append(envelope)\n",
    "\n",
    "    return np.array(envelopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doppler_6_7 = np.repeat(Doppler_6, 7, axis=0)\n",
    "Doppler_7_7 = np.repeat(Doppler_7, 7, axis=0)\n",
    "Doppler_8_7 = np.repeat(Doppler_8, 7, axis=0)\n",
    "\n",
    "envelope_D_6_7 = homomorphic_envelope_processed(Doppler_6_7)\n",
    "envelope_D_7_7 = homomorphic_envelope_processed(Doppler_7_7)\n",
    "envelope_D_8_7 = homomorphic_envelope_processed(Doppler_8_7, fs=10000)\n",
    "\n",
    "envelope_D_6_7_r = np.mean(envelope_D_6_7.reshape(len(envelope_D_6_7), 3750, -1), axis=2)\n",
    "envelope_D_7_7_r = np.mean(envelope_D_7_7.reshape(len(envelope_D_7_7), 3750, -1), axis=2)\n",
    "envelope_D_8_7_r = np.mean(envelope_D_8_7.reshape(len(envelope_D_8_7), 3750, -1), axis=2)\n",
    "\n",
    "\n",
    "ECG_6_rearrange = np.reshape(ECG_6,(len(ECG_6)*7,3750))\n",
    "ECG_7_rearrange = np.reshape(ECG_7,(len(ECG_7)*7,3750))\n",
    "ECG_8_rearrange = np.reshape(ECG_8,(len(ECG_8)*7,3750))\n",
    "\n",
    "ECG_6_normalized = normalize_zero_one(ECG_6_rearrange)\n",
    "ECG_7_normalized = normalize_zero_one(ECG_7_rearrange)\n",
    "ECG_8_normalized = normalize_zero_one(ECG_8_rearrange)\n",
    "\n",
    "envelope_E_6 = homomorphic_envelope_processed(ECG_6_rearrange,fs=1000)\n",
    "envelope_E_7 = homomorphic_envelope_processed(ECG_7_rearrange,fs=1000)\n",
    "envelope_E_8 = homomorphic_envelope_processed(ECG_8_rearrange,fs=1000)\n",
    "\n",
    "\n",
    "pan_envelope_E_6 = pan_tompkins_envelope_processed(ECG_6_rearrange,fs=1000)\n",
    "pan_envelope_E_7 = pan_tompkins_envelope_processed(ECG_7_rearrange,fs=1000)\n",
    "pan_envelope_E_8 = pan_tompkins_envelope_processed(ECG_8_rearrange,fs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(signal):\n",
    "    histogram, _ = np.histogram(signal, bins=64, density=True)\n",
    "    histogram = histogram[histogram > 0]  # Remove zero entries\n",
    "    entropy = -np.sum(histogram * np.log2(histogram))\n",
    "    return entropy\n",
    "\n",
    "def calculate_psd(signal, fs=1000):\n",
    "    f, psd_values = welch(signal, fs=fs, nperseg=1024, scaling='density')\n",
    "    return psd_values\n",
    "\n",
    "ECG_6_rearrange = np.reshape(ECG_6,(len(ECG_6)*7,3750))\n",
    "ECG_7_rearrange = np.reshape(ECG_7,(len(ECG_7)*7,3750))\n",
    "ECG_8_rearrange = np.reshape(ECG_8,(len(ECG_8)*7,3750))\n",
    "\n",
    "entropy_6 = np.array([calculate_entropy(signal) for signal in ECG_6_rearrange])\n",
    "entropy_6=entropy_6.reshape(len(entropy_6),1)\n",
    "entropy_7 = np.array([calculate_entropy(signal) for signal in ECG_7_rearrange])\n",
    "entropy_7=entropy_7.reshape(len(entropy_7),1)\n",
    "entropy_8 = np.array([calculate_entropy(signal) for signal in ECG_8_rearrange])\n",
    "entropy_8=entropy_8.reshape(len(entropy_8),1)\n",
    "\n",
    "psd_6 = np.array([np.mean(calculate_psd(signal)) for signal in ECG_6_rearrange])\n",
    "psd_6=psd_6.reshape(len(psd_6),1)\n",
    "psd_7 = np.array([np.mean(calculate_psd(signal)) for signal in ECG_7_rearrange])\n",
    "psd_7=psd_7.reshape(len(psd_7),1)\n",
    "psd_8 = np.array([np.mean(calculate_psd(signal)) for signal in ECG_8_rearrange])\n",
    "psd_8=psd_8.reshape(len(psd_8),1)\n",
    "\n",
    "skew_6 = np.array([skew(signal) for signal in ECG_6_rearrange])\n",
    "skew_6=skew_6.reshape(len(skew_6),1)\n",
    "skew_7 = np.array([skew(signal) for signal in ECG_7_rearrange])\n",
    "skew_7=skew_7.reshape(len(skew_7),1)\n",
    "skew_8 = np.array([skew(signal) for signal in ECG_8_rearrange])\n",
    "skew_8=skew_8.reshape(len(skew_8),1)\n",
    "\n",
    "kurtosis_6 = np.array([kurtosis(signal) for signal in ECG_6_rearrange])\n",
    "kurtosis_6=kurtosis_6.reshape(len(kurtosis_6),1)\n",
    "kurtosis_7 = np.array([kurtosis(signal) for signal in ECG_7_rearrange])\n",
    "kurtosis_7=kurtosis_7.reshape(len(kurtosis_7),1)\n",
    "kurtosis_8 = np.array([kurtosis(signal) for signal in ECG_8_rearrange])\n",
    "kurtosis_8=kurtosis_8.reshape(len(kurtosis_8),1)\n",
    "\n",
    "std_6 = np.array([np.std(signal) for signal in ECG_6_rearrange])\n",
    "std_6=std_6.reshape(len(std_6),1)\n",
    "std_7 = np.array([np.std(signal) for signal in ECG_7_rearrange])\n",
    "std_7=std_7.reshape(len(std_7),1)\n",
    "std_8 = np.array([np.std(signal) for signal in ECG_8_rearrange])\n",
    "std_8=std_8.reshape(len(std_8),1)\n",
    "\n",
    "We_6 = np.array([np.sum(np.abs(pywt.wavedec(signal, wavelet='db3', level=1))) for signal in ECG_6_rearrange])\n",
    "We_6=We_6.reshape(len(We_6),1)\n",
    "We_7 = np.array([np.sum(np.abs(pywt.wavedec(signal, wavelet='db3', level=1))) for signal in ECG_7_rearrange])\n",
    "We_7=We_7.reshape(len(We_7),1)\n",
    "We_8 = np.array([np.sum(np.abs(pywt.wavedec(signal, wavelet='db3', level=1))) for signal in ECG_8_rearrange])\n",
    "We_8=We_8.reshape(len(We_8),1)\n",
    "\n",
    "Wn_6 = np.array([np.mean(pywt.wavedec(signal, wavelet='db3', level=1)) for signal in ECG_6_rearrange])\n",
    "Wn_6=Wn_6.reshape(len(Wn_6),1)\n",
    "Wn_7 = np.array([np.mean(pywt.wavedec(signal, wavelet='db3', level=1)) for signal in ECG_7_rearrange])\n",
    "Wn_7=Wn_7.reshape(len(Wn_7),1)\n",
    "Wn_8 = np.array([np.mean(pywt.wavedec(signal, wavelet='db3', level=1)) for signal in ECG_8_rearrange])\n",
    "Wn_8=Wn_8.reshape(len(Wn_8),1)\n",
    "\n",
    "Ws_6 = np.array([np.std(pywt.wavedec(signal, wavelet='db3', level=1)) for signal in ECG_6_rearrange])\n",
    "Ws_6=Ws_6.reshape(len(Ws_6),1)\n",
    "Ws_7 = np.array([np.std(pywt.wavedec(signal, wavelet='db3', level=1)) for signal in ECG_7_rearrange])\n",
    "Ws_7=Ws_7.reshape(len(Ws_7),1)\n",
    "Ws_8 = np.array([np.std(pywt.wavedec(signal, wavelet='db3', level=1)) for signal in ECG_8_rearrange])\n",
    "Ws_8=Ws_8.reshape(len(Ws_8),1)\n",
    "\n",
    "\n",
    "max_6 = np.array([np.max(signal) for signal in ECG_6_rearrange])\n",
    "max_6=max_6.reshape(len(max_6),1)\n",
    "max_7 = np.array([np.max(signal) for signal in ECG_7_rearrange])\n",
    "max_7=max_7.reshape(len(max_7),1)\n",
    "max_8 = np.array([np.max(signal) for signal in ECG_8_rearrange])\n",
    "max_8=max_8.reshape(len(max_8),1)\n",
    "\n",
    "min_6 = np.array([np.min(signal) for signal in ECG_6_rearrange])\n",
    "min_6=min_6.reshape(len(min_6),1)\n",
    "min_7 = np.array([np.min(signal) for signal in ECG_7_rearrange])\n",
    "min_7=min_7.reshape(len(min_7),1)\n",
    "min_8 = np.array([np.min(signal) for signal in ECG_8_rearrange])\n",
    "min_8=min_8.reshape(len(min_8),1)\n",
    "\n",
    "mean_6 = np.array([np.mean(signal) for signal in pan_envelope_E_6])\n",
    "mean_6=mean_6.reshape(len(mean_6),1)\n",
    "mean_7 = np.array([np.mean(signal) for signal in pan_envelope_E_7])\n",
    "mean_7=mean_7.reshape(len(mean_7),1)\n",
    "mean_8 = np.array([np.mean(signal) for signal in pan_envelope_E_8])\n",
    "mean_8=mean_8.reshape(len(mean_8),1)\n",
    "\n",
    "Feature_6 = np.concatenate([dtw_dist_lag_6.reshape(len(dtw_dist_lag_6),1), correlations_lag_6.reshape(len(correlations_lag_6),1),entropy_6,psd_6,skew_6,kurtosis_6,std_6,We_6,Wn_6,Ws_6,max_6,min_6,mean_6,Feature_indices_6], axis=1)\n",
    "Feature_7 = np.concatenate([dtw_dist_lag_7.reshape(len(dtw_dist_lag_7),1), correlations_lag_7.reshape(len(correlations_lag_7),1),entropy_7,psd_7,skew_7,kurtosis_7,std_7,We_7,Wn_7,Ws_7,max_7,min_7,mean_7,Feature_indices_7], axis=1)\n",
    "Feature_8 = np.concatenate([dtw_dist_lag_8.reshape(len(dtw_dist_lag_8),1), correlations_lag_8.reshape(len(correlations_lag_8),1),entropy_8,psd_8,skew_8,kurtosis_8,std_8,We_8,Wn_8,Ws_8,max_8,min_8,mean_8,Feature_indices_8], axis=1)\n",
    "\n",
    "Feature_label_all = np.concatenate([Feature_6,Feature_7,Feature_8]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = CatBoostClassifier()\n",
    "loaded_model.load_model('/Users/alirezarafiei/Documents/DopplerGAN/catboost_classifier.cbm')\n",
    "predictions = []\n",
    "Features = [Feature_6,Feature_7,Feature_8]\n",
    "for f in Features:\n",
    "    # Make predictions\n",
    "    preds = loaded_model.predict(f)\n",
    "    predictions.append(preds.T[0].reshape(7,int(len(preds.T[0])/7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['BA120381V2','KF221288V2','SZ290877V2']\n",
    "for j in range(len(subjects)):\n",
    "    for i in range(1,8):\n",
    "        np.savetxt(f'/Users/alirezarafiei/Documents/DopplerGAN/{subjects[j]}_{i}_SQI.txt', predictions[j][i-1], delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
